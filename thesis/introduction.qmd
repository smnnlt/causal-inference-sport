---
title: ''
format: pdf
bibliography: ../references.bib
editor:
  markdown:
    references: 
      location: block
      prefix: "introduction"
---

# Introduction

## Relevance

Empirical research is acquiring knowledge through systematic observations by analyzing data. Data analysis typically encompasses three primary tasks: description, prediction, and causal inference [@hernán2019; @carlin2023]. Description means characterizing features in a subset of a population. Prediction means forecasting outcomes based on available data. Causal inference means making claims about causality – what would have happened under different circumstances.

Most research in sport science is of causal nature. We want to understand how sports works with the ultimate goal to intervene: If we understand why certain people or teams are winning a competition, we can use that knowledge to adjust training and tactics. Likewise, in health contexts, we seek for sport intervention that change an individual's fitness to ultimately increase well-being compared to if no intervention were undertaken. Ultimately, we are interested in potential outcomes --- what would have happened if the team had played different or if the individual had undergone a different training. This exactly is causal thinking.

Research has devised a framework for conducting studies that can infer causality without knowledge of the exact underlying causal mechanisms: the randomized controlled trial (RCT). But in sport science, RCTs are often not feasible, because of the difficulty or undesirability of implementing randomized interventions, particularly in the context of elite sports [@bullock2023]. Consequently, causality must often be inferred through alternative designs, such as observational studies. The field of causal inference offers tools for this particular task.

An association on its own does not inherently indicate causality, echoing the famous adage: "correlation does not imply causation." Associations observed in data may indeed stem from causality, but they can also arise from different types of bias, resulting in spurious associations. Conversely, causation does not necessarily imply correlation. Genuine causal relationships might remain obscured within the data. Distinguishing between associations and causal relationships necessitates looking beyond the data itself.

Causal data analysis requires something that is not relevant to most description and prediction tasks: A scientific model informed by expert-domain knowledge, that depicts the causal nature of the phenomena under investigation. This causal model serves as the foundation for all causal inference. By adhering to the rules implied by the causal model, we can analyze our data in a manner that allows for the estimation of causal effects. Methods of causal inference are vital to estimate causal effects from observational data. But they can also aid in designing and analyzing experiments, and even provide benefits for description and prediction analyses.

As all statistical analyses, causal modeling is not free of assumptions. Those are assumptions about the underlying data, but also about the underlying data generative process (the world in which the data have been created). Causal modeling requires to think more clearly about these assumptions before conducting an analysis, and is in general more transparent in communicating them [@grosz2020]. In a way, this is a more honest way of doing inference than relying on non-causal language when inferring causality was the actual research goal [@hernán2018]. <!-- one sentence? -->

I will start by establishing a working definition of causality and by providing an overview of causal inference as a research field, with its history and popular frameworks. Following this, I will outline recent applications of causal inference across various disciplines with a focus on the (sparse) literature of causal inference in sport science.

## Previous Research

What causality actually means is a merely philosophical question [@illari2014]. For the sake of this thesis, we use the framework of potential outcomes to define causality [@rubin1974]. If we intervene on a variable and this leads to changes compared to if we had not intervened, we can define the intervention as causing the outcome. A causal effect is therefore defined by the comparison between two states, what has actually happened, and what would have potentially happened under different intervention. The intervention itself does not need to be actually possible to conduct, it can be purely hypothetical. For example, e.g., if we define the causal effect of biological sex on endurance performance we are actually asking: If we could intervene on an individual's sex (by changing it), what difference in endurance performance would we expect. We can state this without actually being able to change biological sex (when defined via chromosome[^introduction-1]).

[^introduction-1]: This "defined via X" is exactly the reason why @imbens2015 would oppose the effect of sex on endurance performance as being a causal statement. Their argument is that this example does not clarify what intervening on sex would actually mean. It could be (hypothetically) intervening on chromosomes, on genitalia, or on hormones. According to their view, this ambiguousness makes the statement ill-defined so that it cannot serve as a causal statement. For this thesis I follow a less strict approach in allowing causal statements that rely on (hypothetical) intervention, even if the intervention is not clearly decisive from the statement alone.

It can be easy to define causal effects, but difficult to estimate them. For estimation, we can only use real data and not hypothetical. We still want to estimate the difference between potential outcomes, with the caveat that for each unit of observation we only have one actual outcome available. Essentially, causal inference can be viewed as a missing data problem [@ding2018]. The most straightforward way to deal with this problem is using a randomization controlled research design[^introduction-2], but often this is impossible or impractical.

[^introduction-2]: See @sec-math for the mathematical rationale behind this.

@fisher1925 was the first to suggest randomization as the basis to inference of causal effects in experiments. Randomized controlled designs quickly became the gold standard of experimental research [@cochran1957]. Possibly until the 1970s it remained the common view that causal effects can only validly studied in randomized experiments, and not in observational studies. But based on the earlier invention of potential outcome notation by @neyman1923, @rubin1974 provided a framework for estimating causal effect from both experimental and observation data. This framework later termed the 'Rubin Causal Model' [@holland1986] remains one of the predominant approaches to causal inference from observational data (see @sec-math for the mathematical notation of this framework).

Another approach to causal inference is the use of graphical models. Pioneered by Pearl [-@pearl1993; @pearl1995], directed acyclic graphs (DAGs) have become a popular tool to assist estimating causal effects. They serve as an easy tool to aid estimating causal effect [@shrier2008]. The graph-based approach has been criticized for being unnecessary [@rubin2022] or requiring a vast of (often not considered) assumptions [@dawid2010], yet it is popular in many fields [@morgan2014]. Other approaches to causal inference aim to bring the potential outcome framework into a graph form [@richardson2013], or are less structural in that they neither require potential outcomes nor graphs [@dawid2000]. Discussion about the different frameworks of causal inference can be found elsewhere. In this thesis I will often follow Pearl's graph-based approach [@pearl2009], because it is in my view the most intuitive and accessible way of learning causal inference[^introduction-3], but I will also consider ideas and specific methods from the potential outcome framework [@angrist2009].

[^introduction-3]: Naturally, the proponents of other frameworks will disagree on this. E.g., Rubin argues that teaching in the potential outcome framework is the easiest way to introduce researchers to causal inference [see his comment in @dawid2000]. But the vast majority of newer applied introductory texts are built on the graph based approach [e.g., @cunningham2021; @rohrer2018; @shrier2008]. I think the success of these texts speak for the accessibility of graph-based approaches for causal inference.

Causal inference, whether in the framework of potential outcomes or graphical representations is considered one of the most influential statistical ideas of the past decades [@gelman2021]. While the potential outcome framework dominates contemporary economic research [@imbens2020], graph-based causal inference has gained wide popularity in other fields, such as epidemiology [@greenland1999; @tennant2021], psychology [@rohrer2018], and sociology [@morgan2014]. These fields share similar challenges with sport science: They study complex systems (i.e., humans) and often have to rely on observational data for inference. Despite its potential value, the use of causal inference in sport science is so far limited.

It is unsurprisingly that the most active research areas of causal inference in sport science are at the intersection to the field of epidemiology [@lynch2020], mostly in the area of injury research. For researching the prevention of injuries, calls to use causal modeling are frequent [@shrier2007; @nielsen2020; @kalkhoven2024], but its actual use is rare [@rommers2021]. @shrier2007 and @hopkins2008 were the first to propose graphical causal models for sport science. The unusual presentation in form of a slideshow by @hopkins2008, the narrow scope on injuries by @shrier2007, and the lack of an accessible and focused reasoning by both may have limited the impact of their ideas. Recently, @steele2020 undertook a new try to highlight the need of causal thinking and modeling in sport science. Embedded in a general model of sport research [@bishop2008], they used an example of strength training to introduce key elements of causal inference such as potential outcomes and causal graphs. But they rather focused on the process of answering a specific research question (in part utilizing causal inference tools) rather than explicitly introducing causal inference to sport science.

In a recent extensive debate revolving around the causal effect of muscle hypertrophy on strength, all author groups agreed on the difficulties of distinguishing associations and causal relations, and the challenge of adequately controlling experiments or using observational data for causal statements [@dankel2018; @balshaw2017; @buckner2017; @loenneke2019; @taber2019]. Yet none of them mentioned causal inference as a potential way to deal with these problems until a later publication by @nuzzo2019, again exemplifying the potential usefulness, but currently low dissemination of causal inference methods in sport science. In a recent article, @kalkhoven2024 calls for the use of graphical causal models in sports injury research. @kalkhoven2024 concludes his text with an appeal to all sport scientist to engage with the field of causal inference. This thesis will provide sport-scientist with an accessible, field-specific introduction to causal inference.

## Aim

The aim of this thesis is to bring the methods of causal inference to sport science. The overachieving goal is to demonstrate the utility and necessity of causal inference methods for data analysis in sport science. I start with demonstrate key concepts of causal models using directed acyclic graphs by introducing confounders, colliders, and conditioning rules. I then revisit two published observation studies from the field of endurance running from a causal inference perspective. Finally, I will discuss opportunities that causal inference brings to sport science as well as challenges and limitations of adopting such approaches.

I aim to make the thesis as accessible as possible to readers who are new to causal inference. Detailed methodologies of modeling and mathematical formulations will be included in the appendices. My objective is to ensure that the thesis is understandable for any sport scientist with some basic statistical education. Instead of critiquing current statistical practices in sport science, the objective of this work is to showcase the effectiveness of methods that extend beyond these practices.
